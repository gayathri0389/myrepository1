{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "432f83dd-ce3c-482a-b12f-ae281e852f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: stem in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (1.8.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: requests[socks] in c:\\programdata\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]) (2024.2.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]) (1.7.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests[socks] stem beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34fba070-652d-484d-bfed-8b519036f1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stem import Signal\n",
    "from stem.control import Controller\n",
    "\n",
    "def renew_tor_ip():\n",
    "    with Controller.from_port(port=9051) as controller:\n",
    "        controller.authenticate()  # No password needed for default Tor setup\n",
    "        controller.signal(Signal.NEWNYM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60bdf8de-e370-4524-8031-d6a4757ff30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_tor_session():\n",
    "    \"\"\"\n",
    "    Create a session that routes traffic through the Tor network.\n",
    "    \"\"\"\n",
    "    session = requests.Session()\n",
    "    session.proxies = {\n",
    "        'http': 'socks5h://127.0.0.1:9050',\n",
    "        'https': 'socks5h://127.0.0.1:9050',\n",
    "    }\n",
    "    return session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "653d140b-918d-4cf1-923b-a888619f5a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_dark_web(url):\n",
    "    \"\"\"\n",
    "    Fetch the HTML content of a dark web URL using Tor.\n",
    "    \"\"\"\n",
    "    session = get_tor_session()  # Create a Tor session\n",
    "    try:\n",
    "        response = session.get(url, timeout=15)  # Fetch the URL\n",
    "        response.raise_for_status()  # Raise an error if the request fails\n",
    "        return response.text  # Return the HTML content\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e44b614b-d3b9-4ee6-8dc8-abbfc1bdd9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tor IP address has been renewed.\n",
      "<!DOCTYPE html>\n",
      "<!--[if IE 7]>\n",
      "<html class=\"ie ie7\" lang=\"en-US\" prefix=\"og: http://ogp.me/ns#\">\n",
      "<![endif]-->\n",
      "<!--[if IE 8]>\n",
      "<html class=\"ie ie8\" lang=\"en-US\" prefix=\"og: http://ogp.me/ns#\">\n",
      "<![endif]-->\n",
      "<!--[if !(IE 7) | !(IE 8)  ]><!-->\n",
      "<html lang=\"en-US\" prefix=\"og: http://ogp.me/ns#\" >\n",
      "\n",
      "<!--<![endif]-->\n",
      "<head>\n",
      "<meta charset=\"UTF-8\" />\n",
      "\n",
      "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, minimum-scale=0.5, maximum-scale=3.0\"> \n",
      "<link rel=\"shortcut icon\" href=\"https://media.geeksforgeeks.org/wp-content/cdn-uploads/gfg_favicon.png\" type=\"image/x-icon\" />\n",
      "\n",
      "<link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n",
      "<link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n",
      "\n",
      "\n",
      "<meta name=\"theme-color\" content=\"#308D46\" />\n",
      "<meta name='robots' content='index, follow, max-image-preview:large, max-snippet:-1' />\n",
      "\n",
      "<meta name=\"image\" property=\"og:image\" content=\"https://media.geeksforgeeks.org/wp-content/cdn-uploads/gfg_200x200-min.png\">\n",
      "<met\n"
     ]
    }
   ],
   "source": [
    "# Test the setup\n",
    "def renew_tor_ip():\n",
    "    from stem import Signal\n",
    "    from stem.control import Controller\n",
    "    try:\n",
    "        with Controller.from_port(port=9051) as controller:\n",
    "            controller.authenticate()\n",
    "            controller.signal(Signal.NEWNYM)\n",
    "            print(\"Tor IP address has been renewed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error renewing IP: {e}\")\n",
    "\n",
    "renew_tor_ip()  # Optional: Renew the Tor IP\n",
    "\n",
    "dark_web_url = \"https://www.geeksforgeeks.org/darkscrape-osint-tool-for-scraping-dark-websites/\"  # Test URL\n",
    "html_content = scrape_dark_web(dark_web_url)\n",
    "\n",
    "if html_content:\n",
    "    print(html_content[:1000])  # Print the first 1000 characters of the HTML\n",
    "else:\n",
    "    print(\"Failed to fetch the content.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "211394a5-566f-4afe-af59-c58845a694ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Title: DarkScrape - OSINT Tool For Scraping Dark Websites - GeeksforGeeks\n",
      "Found 423 links:\n",
      "#main\n",
      "https://www.geeksforgeeks.org/\n",
      "https://www.geeksforgeeks.org/courses/dsa-to-development-coding-guide?itm_source=geeksforgeeks&itm_medium=main_header&itm_campaign=courses\n",
      "https://www.geeksforgeeks.org/courses/data-science-live?itm_source=geeksforgeeks&itm_medium=main_header&itm_campaign=courses\n",
      "https://www.geeksforgeeks.org/courses/mastering-generative-ai-and-chat-gpt?itm_source=geeksforgeeks&itm_medium=main_header&itm_campaign=courses\n",
      "https://www.geeksforgeeks.org/courses/search?query=AWS&itm_source=geeksforgeeks&itm_medium=main_header&itm_campaign=courses\n",
      "https://www.geeksforgeeks.org/courses/dsa-self-paced?itm_source=geeksforgeeks&itm_medium=main_header&itm_campaign=courses\n",
      "https://www.geeksforgeeks.org/courses/Data-Structures-With-Python?itm_source=geeksforgeeks&itm_medium=main_header&itm_campaign=courses\n",
      "https://www.geeksforgeeks.org/courses/data-structures-and-algorithms-in-javascript?itm_source=geeksforgeeks&itm_medium=main_header&itm_campaign=courses\n",
      "https://www.geeksforgeeks.org/courses/cpp-programming-basic-to-advanced?itm_source=geeksforgeeks&itm_medium=main_header&itm_campaign=courses\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def parse_html(html_content):\n",
    "    \"\"\"\n",
    "    Parse HTML content and extract meaningful data.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Example: Extract the page title\n",
    "    page_title = soup.title.string if soup.title else \"No title found\"\n",
    "    print(f\"Page Title: {page_title}\")\n",
    "\n",
    "    # Example: Extract all links\n",
    "    links = [a['href'] for a in soup.find_all('a', href=True)]\n",
    "    print(f\"Found {len(links)} links:\")\n",
    "    for link in links[:10]:  # Print the first 10 links\n",
    "        print(link)\n",
    "\n",
    "    return page_title, links\n",
    "\n",
    "# Parse the fetched HTML\n",
    "page_title, links = parse_html(html_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a96c11ee-3978-483b-a7a3-ae39c8f17bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to scraped_data.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def save_data(page_title, links, filename=\"scraped_data.json\"):\n",
    "    \"\"\"\n",
    "    Save the scraped data to a JSON file.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        \"page_title\": page_title,\n",
    "        \"links\": links\n",
    "    }\n",
    "\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "save_data(page_title, links)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc59677-abfe-4d76-af02-9075b9c87a18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
